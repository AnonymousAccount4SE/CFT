# Readme
# --
<<<<<< EOF

Standard model of particle physics 
----------------------------------
Toying with identifying ways to unify particle energies, by first doing a normalization
of the values, through some repeated transformation, then calculate variance of the set,
looking for normalization parameter(s) or algorithm that give smallest variance.

Comparing this with random sets of data of same size as the particle energies, and see for
what fraction of the data sets we manage finding a variance as low as the lowest
variance for the real (particle energies) data, to get a sense of whether the particle
energy values feels random or not.

First attempt
-------------
Normalization by multiplying repeatedly with factor in range 0-0.8, we found that the
smallest variance is 204.33 for factor 0.6866

Factors very close to 1.0 will result in creeping the values slowly down below our limit
and produce artificial correlations, hence stopping at 0.8 og 0.85

For random data sets undergoing the same transformation, we find that smallest variance
for each set under 204.33 is found in about 5% of the cases. 

	The random data produces a lowest variance of around 700 (average)
  	The real data provides lowest variance of 204
  	The random data provides variance lower than this for about ~4-5% of the random data sets,
    increasing to 7% by tweaking scale factor.

	Error sources: the scale factor for the random data affects the outcome!


Second attempt
--------------
Doing repeat square root until value in range

For particle data we get variance of 43300. When checking random data sets, we get that
around 90% of those have Sqrt variance lower than this value, reduces this to 60% by
tweaking scale factor.
	
	Error sources: result varies by scale factor for random data.


Other transformations
---------------------
- logarithmic
- square root
- rotate complex vector along inwards spiral until absolute length at certain value, then read out
  real value
- cos/sin with offsets


Functions
---------
   - "r" - set range
   - "s" - search range, looking for minimum variance
   - "h" - show histogram for current range
   - "rand" - get lowest variance for random data sets of same length as real data

Currently focused on quarks only.


>>>>>> EOF
->line
	println("| " + line)
/Readme

P(1)*1000 
/K

P(1)*1000000
/M

P(1)*1000000000
/G

# Define range
# --
	readLine("Start value").parseFloat=>start
	readLine("End value").parseFloat=>end
	if (start < 0.05) start=0.05
	if (end > 0.95) end=0.95

	SymDict(start,end) => data
	Db2:Set(Sys.scriptId,"range",data)
/SetRange



# Get range
# --
	Db2:Get(Sys.scriptId,"range") => result
	if (result==null) {
		SetRange
		result=GetRange
	}
	result
/GetRange



# Data
# --
	P(1,false)=>random
	
	Sequence(
		M(2.2)   # up
		G(1.28)  # charm
		G(173.1) # top
		M(4.7)   # down
		M(96)    # strange
		G(4.18)  # bottom
	) => actualValues
	
	
	if (random) {
		Inner {
			actualValues->x  # to produce same number of values
				v=Lib.Util.random*10000000000000.0
				out(v)
		}
	} else {
		actualValues
	}

/Data

# Sin(45) = Sqrt(2)/2
# --
	0.707106781186
/factor


# Normalize value by multiplying with factor
# --
	P(1,100000) => value
	P(2,0.5)=> factor
	P(3,1000) => range

	loop
		break(value<range)
		value=value*factor
	|
	value
/NormalizeValue_Factor


# Normalize value by square root
# --
	P(1,100000) => value
	P(2,1000) => range

	loop
		break(value<range)
		value=Lib.Math.sqrt(value)
	|
	value
/NormalizeValue_Sqrt



# Process data set by multiplying with factor in range 0-1
# --
	P(1,0.5)=>factor
	P(2,Data)=>data
	data->value
		out(NormalizeValue_Factor(value, factor))
/NormalizeSet_Factor


# Process data set by doing square root
# --
	P(1,Data)=>data
	data->value
		out(NormalizeValue_Sqrt(value))
/NormalizeSet_Sqrt





# Calculate variance of set
# --
	P(1,List(1,2,3))=>data
	sum=0
	data->x sum=sum+x |
	avg=sum/data.length
	varianceSum=0
	data->x 
		diff=if(x>avg, x-avg, avg-x)
		varianceSum=varianceSum + (diff*diff)
	|
	# return value
	varianceSum / data.length
/Variance



# Fix presentation of floats
# --
	P(1,3.14159265) => value
	P(2,5) => numDecimals
	s=""+value
	pos=s.indexOf(".")
	if (pos < 0) s=s+".000000000000000000000"
	pos=s.indexOf(".")
	s=s.sub(0,pos+1+numDecimals)
/fix





# Find lowest variance for current range
# --
	P(1,false)=>random
	
	lowestVariance = 999999
	lowestVarianceFactor = 0

	highestVariance=0
	highestVarianceVactor=0

	STEPS=30000
	theData=Data(random)

	range=GetRange
	Lib.Data.for(range.start, range.end, (range.end-range.start)/STEPS)->factor
		data = NormalizeSet_Factor(factor,theData)
		var = Variance(data)
		if (var < lowestVariance) {
			lowestVariance=var
			lowestVarianceFactor=factor
		}
		if (var > highestVariance) {
			highestVariance=var
			highestVarianceFactor=factor
		}
		println("factor=" + fix(factor,12) + " variance=" + fix(Variance(data),12))

	|
	println("--")
	println("LOW  factor="+fix(lowestVarianceFactor,12) + " variance=" + fix(lowestVariance,12))
	println("HIGH factor="+fix(highestVarianceFactor,12) + " variance=" + fix(highestVariance,12))

	println("--")
	println("Sqrt: " + Variance(NormalizeSet_Sqrt(theData)))

	lowestVarianceFactor
/Search




# Show for specific factor
# --
	P(1,readLine("Enter factor").parseFloat) => factor
	if (factor > 1) factor=1/factor
	if (factor < 0.05) factor=0.05
	if (factor > 0.95) factor=0.95

	data = NormalizeSet_Factor(factor)
	data->x
		println(x)
	|
	println
	println("Factor=" + factor)
	println("Variance=" + Variance(data))
	true
/Show
	


# Visualize
# --
	range=GetRange
	LINES=Term.h
	Lib.Data.for(range.start, range.end, (range.end-range.start)/LINES)->factor
		data = NormalizeSet_Factor(factor)
		var = Variance(data)
		out(AValue("",var,SymDict(factor)))
	| => values

	WIDTH=Term.w-11
	max=0
	values->v if(v.v>max) max=v.v |
	factor=WIDTH/max
	values->v
		len=(v.v*factor).i
		Lib.Data.yes(len,"#").concat => bar
		fStr=(""+v.meta.factor+"00000000").sub(0,8)
		println(fStr + " " + bar)
/Histogram



# Examine random data sets
# --
	P(1,204)=>realDataVariance
	P(2,100)=>maxCount
	P(3,43342)=>realSqrtVariance
	
	count=0

	
	countUnderRealValue=0
	countUnderRealSqrtValue=0

	loop
		break(count >= maxCount)
		count=count+1
		
		if (count % 50 == 0) {
			println("[" + count + "] <FactorMinVar: " + fix(countUnderRealValue/count*100,4) + "%"
				+ " <SqrtMinVar: " + fix(countUnderRealSqrtValue/count*100,4) + "%")
		}
		theData=Data(true)

		Inner{
			xx=Variance(NormalizeSet_Sqrt(theData))
			if (xx < realSqrtVariance) countUnderRealSqrtValue=countUnderRealSqrtValue+1
		}

		
		STEPS = 1000
		
		lowest=99999999
		range=GetRange
		Inner {
			Lib.Data.for(range.start, range.end, (range.end-range.start)/STEPS)->factor
				data=NormalizeSet_Factor(factor, theData)
				var=Variance(data)
				if (var<lowest) lowest=var
		} 
		#println("count="+count + " lowestVar=" + fix(lowest,3))
		if (lowest<realDataVariance) {
			countUnderRealValue=countUnderRealValue+1
		}
		out(lowest)
	| => data
	
	println("[" + count + "] Under real data variance value: " + fix(countUnderRealValue/count*100,4) + "%")

	sum=0
	lowest=9999999999
	data->value
		if (value<lowest) lowest=value
		sum=sum+value
	|
	println("Average=" + sum/data.length)

	println("Under real sqrt lowest variance=" + fix(countUnderRealSqrtValue/count*100,4) + "%")
/CheckRandomData



SetRange
/r

Search
/s

Search(true)
/sr

Histogram
/h


# Interactive front to CheckRandomData
# --
	Input("Lowest variance for real data").get.parseFloat => lowestVar
	Input("Sqrt variance for real data").get.parseFloat => lowestSqrt
	Input("Number of random data sets").get.parseInt => count

	CheckRandomData(lowestVar,count,lowestSqrt)
/rand

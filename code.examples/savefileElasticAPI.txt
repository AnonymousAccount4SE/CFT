# Readme
<<<< EOF
-------------------------------------------------------------
Simple script library for interfacing a running
ElasticSearch node (or cluster via one of its nodes),
through the REST API.

Initially asks for host+port on format xxx:NNN, then stores
this in database. 

To change to different host name, call MyHost(true)
-------------------------------------------------------------
>>>> EOF
/Readme


# Get/set hostname
# --
	P(1,false) => change

	Db2:Get("ElasticAPI","host") => name

	if (name==null || change) {
		Input("Enter elasticsearch host:port (usually :9200)").get => name
		error(!name.contains(":"), "Missing :PORT")
		Db2:Set("ElasticAPI","host",name)
	}
	name
/MyHost


# List indexes
	Util:CURL(MyHost,"GET","/_cat/indices?pretty",null,true)
/ListIndexes


# Create index
	P(1,Input("Create index name").get) => name

	Dict.set("settings",Dict
		.set("number_of_shards",1)
		.set("number_of_replicas",1)
	) => data

	url = "/"+name+"?pretty"		
	Util:CURL(MyHost,"PUT", url, data, true)
/CreateIndex


# Check lifecycle progress
	Util:CURL(MyHost,"GET","/.ds-timeseries-*/_ilm/explain")
/LifecycleProgress


# Create Index Lifecycle Policy
# --
	P(1,"RFTest")=>ilpName
	P(2,30)=>expirationDays

	SymDict(expirationDays).mergeCodes => data

<<<<<<<< EOF
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "set_priority": {
            "priority": 100
          }
        }
      },
      "delete": {
        "min_age": "${expirationDays}d",
        "actions": {
          "delete": {
            "delete_searchable_snapshot": true
          }
        }
      }
    }
  }
}
>>>>>>>> EOF
	->line out(line.merge(data).trim)
	| _.concat(" ") => json

	url="/_ilm/policy/" + ilpName
	Util:CURL(MyHost,"PUT",url,json,true)
/CreateILP




# Create Index Template and link it to Index Lifecycle Policy
# --
	P(1,"main2*") => indexPattern
	P(1,"OneMonth") => lifeCycleName

	Dict
		.set("index_patterns",List(indexPattern))
		.set("template",Dict
			.set("settings",Dict
				.set("number_of_shards",1)
				.set("number_of_replicas",1)
				.set("index.lifecycle.name",lifeCycleName)
				.set("index.lifecycle.rollover_alias","timeseries")
			)
		)
	=> data
		
	json=JSON:Export(data)
	println(json)
	println
	Util:CURL(MyHost,"PUT","/_index_template/main2?pretty",json,true)
		
/CreateIndexTemplate



# Delete dated indexes older than N days
# --
	P(1,30)=>keepDays
	P(2,60)=>scanSinceDays
	P(3,Lambda{P(1,Date)=>date error("Lambda not implemented")}) => LIndexName
		# The lambda takes a Date object, and should return an index name
		# for that day.
	P(4,false)=>enable
		# Leave false while testing, set to true to call DELETE

	Lib.Data.for(scanSinceDays,keepDays,-1)->daysAgo
		date = Date.sub(Date.Duration.days(daysAgo))
		indexName=LIndexName.call(date)
		Lib:Header("Deleting index: " + indexName)
		if (enable) {
			Util:CURL(MyHost,"DELETE","/"+indexName,null,true)
		}
/DeleteIndexes


# Delete day-indexes named on format main2-yyyy.MM.dd or similar
# --
	P(1,"main2-")=>prefix
	P(2,"yyyy.MM.dd")=>dateFormat
	P(3,30)=>keepDays
	P(3,60)=>scanSinceDays	

	SymDict(prefix,dateFormat).set("LIndexName",
		Lambda {
			P(1)=>date
			self.prefix + date.setFormat(self.dateFormat).fmt
		}
	) => obj
	DeleteIndexes(keepDays,scanSinceDays,obj.LIndexName,true)
/DeletePrefixedDatedIndexes


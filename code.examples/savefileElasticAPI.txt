# License
<<< EOF
#
# CFT - an interactive programmable shell for automation 
# Copyright (C) 2020-2022 Roar Foshaug
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 of the License.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>
#
>>> EOF
/License

# Readme
<<<< EOF
-------------------------------------------------------------
Simple script library for interfacing a running
ElasticSearch node (or cluster via one of its nodes),
through the REST API.

Initially asks for host+port on format xxx:NNN, then stores
this in database. 

To change to different host name, call MyHost(true)

#Note: the Util:CURL function has problems with JSON data
# on windows. Works fine on Linux / WSL

-------------------------------------------------------------
>>>> EOF
/Readme

# Get/set target hostname
# --
    P(1,false) => change

    Db2:Get("ElasticAPI","host") => name

    if (name==null || change) {
        println("Enter elasticsearch host[:port] (port defaults to 9200)")
        
        readLine("host:port") => name
        if(!name.contains(":")) name=name+":9200"
        Db2:Set("ElasticAPI","host",name)
    }
    name
/MyHost



# Change target hostname
# --
    MyHost(true)
/ChangeMyHost




# Create Kibana URL
# --
    MyHost.before(":") + ":5601/app/kibana"
/KibanaURL



# List indexes
# --
    Util:CURL("http",MyHost,"GET","/_cat/indices?format=json&pretty=true",null,false).stdout

/ListIndexes


# Create index with lifecycle management
# --
    P(1,Input("Index name xxx-1 or similar").get) => indexName
	P(2,Input("index.lifecycle.name").get) => ilpName
	P(3,Input("index.lifecycle.rollover_alias").get) => ilpAlias

	

    Dict.set("settings",Dict
		.set("number_of_shards",1)
		.set("number_of_replicas",1)
		.set("index.lifecycle.name", ilpName)
		.set("index.lifecycle.rollover_alias", ilpAlias)
	).set("aliases",Dict
		.set(ilpAlias, Dict
			.set("is_write_index", true)
		)
	)
	=> data

	if (ilpName != "") {
		data.settings
	}

    url = "/"+indexName+"?pretty" 

	println("url=" + url)       
	Inner{
		JSON:PP(data)->line println(line)
	}

    Util:CURL("http",MyHost,"PUT", url, data, true)
/CreateIndex


# Add data WITH timestamp on yyyy-MM-dd'T'HH:mm:ss format, 
# in order to enable time searches, into time-separated indexes,
# which enables manual delete of old data!
# --
	P(1,Input("Index name").get) => indexName
	P(2,Input("Sleep ms").get.parseInt) => delay

	i=0
	loop
		i=i+1
		Util:Counter("customer_id") => recordId

		value=(Lib.Math.sin(i)*100).i

		Date.sub(Date.Duration.hours(1)).setFormat("yyyy-MM-dd'T'HH:mm:ss").fmt => timestamp

		data = Dict.set("name","Roar")
			.set("timestamp", timestamp)
			.set("value",value)

		json=JSON:PP(data).concat(" ")
		println("i="+i)
		#Inner {
		#	json->line println(line)
		#}

		println(json)

		Util:CURL("http",
			MyHost,
			"POST",
			"/" + indexName + "/_doc/"+recordId, 
			json,
			false
			)

		Sys.sleep(delay)
/AddIndexData



# Add data into time-separated indexes, as decided via Date format string
# --
	P(1,Input("Index name").get) => indexName
	P(2,Input("Sleep ms").get.parseInt) => delay
	P(3,Input("Date/Time pattern").setCurr("yyyy-MM-dd-HH-mm").get)=>dateFormat

	i=0
	loop
		i=i+1
		Util:Counter("customer_id") => recordId

		value=(Lib.Math.sin(i)*100).i

		Date.sub(Date.Duration.hours(1)).setFormat("yyyy-MM-dd'T'HH:mm:ss").fmt => timestamp
		data = Dict.set("name","Roar")
			.set("value",value)
			.set("timestamp",timestamp)

		json=JSON:PP(data).concat(" ")
		println("i="+i)

		println(json)

		indexDatePart=Date.setFormat(dateFormat).fmt

		Util:CURL("http",
			MyHost,
			"POST",
			"/" + indexName + "-" + indexDatePart + "/_doc/"+recordId, 
			json,
			false
			)

		Sys.sleep(delay)
/AddMultiIndexData





# Create or modify Index Lifecycle Policy - using minutes for testing
# NOTE: can ILP only be applied to Index that contains time field?
# --
    P(1,Input("Index Lifecycle Policy name").setCurrCond("RFTest").get) =>ilpName
    P(2,Input("Expiration minutes").get.parseInt)=>expirationMinutes
	
	rolloverMinutes=(expirationMinutes/3).i
	
	# Seems the rollover-part is not changed when running function
	# repeatedly, while the delete-part is.
	#
	# Deleting the policy from inside Kibana, then recreating it
	# with this function, we get it correct!

<<<<<<<< EOF
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_age": "<< rolloverMinutes >>m",
            "max_size": "2mb"
          }
        }
      },
      "delete": {
        "min_age": "<< expirationMinutes >>m",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
>>>>>>>> EOF
	=> lines
	lines.mergeExpr->line out(line.trim) | _.concat(" ") => json
   
	# Show JSON
	Inner { JSON:PP(JSON:Parse(json))->line println(line) }

    url="/_ilm/policy/" + ilpName
    Util:CURL("http",MyHost,"PUT",url,json,false)
/ILPCreate



# Check lifecycle progress
# --
	P(1,Input("Index name or pattern").setCurr("*").get) => index
    json = Util:CURL("http",MyHost,"GET","/" + index + "/_ilm/explain").stdout
	JSON:PP(JSON:Parse(json))
/ILPProgress




# List ILP's
# --
	Util:CURL("http",MyHost,"GET","/_ilm/policy").stdout => json
	JSON:PP(JSON:Parse(json))
/ILPList


# Create Index Template - this is needed to connect indexes to ILM Policies
# https://www.elastic.co/guide/en/elasticsearch/reference/7.7/indices-templates.html
#
# Following this step, in kibana, go to Index Lifecycle policies, then 
# for our life cycle, select Action, then Add Policy to Index Template
#
# --
    P(1,Input("Index pattern").get) => indexPattern
	P(2,Input("Index template name").get) => templateName
<<< EOF
{
  "index_patterns": ["<< indexPattern >>"],
  "settings": {
    "number_of_shards": 1
  },
  "mappings": {
    "_source": {
      "enabled": false
    },
    "properties": {
      "host_name": {
        "type": "keyword"
      },
      "created_at": {
        "type": "date",
        "format": "EEE MMM dd HH:mm:ss Z yyyy"
      }
    }
  }
}
>>> EOF
	_.mergeExpr->line out(line.trim) | _.concat(" ") => json

    println(json)
    println
    Util:CURL("http",MyHost,"POST","/_template/" + templateName + "?pretty",json,true)
        
/CreateIndexTemplate


# Delete time-stamped index, named on format <prefix><date>
# --
    P(1,Input("Get index prefix up to date string").get)=>prefix
    P(2,"yyyy-MM-dd")=>dateFormat
    P(3,Date.sub(Date.Duration.days(30)))=>cutoffDate

	json=Util:CURL("http",MyHost,"GET","/_cat/indices?format=json&pretty=true",null,false).stdout
	data=JSON:Parse(json)
	# should be a list of index objects

	error(getType(data) != "List", "Expected list, got " + getType(data))

	# Iterate over indexes, and from their name, parse the date/time.
	# For those older than cutoffDate: delete
	data->ix
		indexName=ix.index
		assert(indexName.startsWith(prefix))
		indexName.sub(prefix.length) => datePart
		println("Index-name: " + indexName + " date/time-part: " + datePart)
		Date.setFormat(dateFormat).parse(datePart) => indexDate

		if (indexDate.before(cutoffDate)) {
			println("* Deleting index " + indexName)
			Util:CURL("http",MyHost,"DELETE","/"+indexName,null,false)
		} 
/DeleteDatedIndexes


# Test DeleteDatedIndexes
# --
	DeleteDatedIndexes("roar1-", "yyyy-MM-dd-HH-mm", Date.sub(Date.Duration.minutes(10)))
/t




# Index Lifecycle Policy README
# --
<<<<<< EOF

Setting up ILP before creating index
-------------------------------------
- Create Index Lifecycle Policy
- Run CreateIndex, entering the name, and an alias

The alias is mandatory. Don't know what it's used for.

The index had to be named xxx-N or we got an error
when it got time to do roll over. Called it main-1 

Note that the error above didn't show up before trying
to execute the ILP. Good thing it had short timeouts.

When it became time to roll over, it then created an 
index main-0000002, which was empty, and
after a further while, it reset the the main-1, purging
all content. 

So the ILP was doing something, just not anything
meaningful.
 

Setting up ILP for existing index
---------------------------------
NOTE: does not work at all! :-)

- Create index with some timestamp on format

		yyyy-MM-dd'T'HH:mm:ss

	** possibly not required for ILP, but good for displaying
	   data along time axis, to see if ILP does anything)

- When creating Kibana Index Pattern, use this field as time field
	This enables presenting data on time axis (when exploring etc)


- Create Index Template under Index management -> Index Templates
	- give index patterns for the indices it controls 


- Create Index Lifecycle Policy
	- Actions: Add policy to Index template


*** Use date pattern in indexes
-------------------------------
Requires external scripting to purge old data
BUT IT WORKS!
See functions

- AddMultiIndexData
- DeleteDatedIndexes




>>>>>> EOF
	-> line println("| " + line)
/ILPReadme

